# Cbench-Skew
Job scheduler for analysis of compression output files, with examples using
skew analysis.

## Job scheduling
The main goal for this package is to run different configurations of jobs that
analyze the output hdf5 files from CBench. To do this, run the
`cbench_skew.multi_stage` module:
```shell
> python -m cbench_skew.multi_stage \
      --script data/example_skew_script.json
      --cbench nyx_imb_compression_test2.json
```
`--script` is a configuration file, and `cbench` is the json file used to run
the CBench analysis that generated the input files. This will run every
permutation of the command line options specified in the configuration file, on
every input file generated by CBench. It prints the commands that would be run
and generates an output json file with jobs to be run.

The name of the output json file is specified in the configuration, but running
the jobs in it looks something like,
```shell
python -m cbench_skew.run --jobs data/example_output.json
```

The only file that the user specifically needs to create to use this package is
the configuration file specified in the script option. The stages are specified
in a dictionary where each key is the executable to run for a stage, and the
value is a configuration dictionary for that stage. This value has an argument
dictionary and a list of prerequisites. The output and output directory are
specified in addition to the stages.

Of particular interest are the argument dictionaries. These are keys (argument
options) to lists, and each argument in each list will be run. These
permutations are computed by the library and run on each input file - and this
is automatically done at each stage based on the output files of the last
stage. See `data/example_skew_sript.json` for an example.

The prequisite option is required and can simply be an empty list. It exists to
provide an interface allowing the user to specify an order to the jobs, such
that the library may compute a dependency tree (similar to make) and run jobs
in parallel. However, this has not yet been implemented.

## Example skew analysis
This library also comes with some example scripts to run with the job
scheduler. The first computes a histogram of the input file, and the second
takes that histogram and plots it. This demonstrates how stages communicate
in this paradigm. The example job script runs these automatically, but they can
also be run explicitly, in a few different ways:

## Method 1
Run Stage 1, computing the histogram and writing to a file.
Then run Stage 2, reading the histogram and plotting it.
```shell
> python -m cbench_skew.stage1 \
      --input data/test.hdf5 \
      --dataset default --bins 20 \
      --output data/histogram.npy

> python -m cbench_skew.stage2 \
      --input data/histogram.npy \
      --color Blues_d \
      --output data/test
```

## Method 2
Run everything at once, bypassing histogram-to-disk.
```shell
> python -m cbench_skew \
      --input data/test.hdf5 \
      --dataset default --bins 20 \
      --output data/test --color Blues_d
```

## Method 3
Run the package in a Python script, again bypassing histogram-to-disk.
```python
from cbench_skew.stage1 import hist
from cbench_skew.stage2 import plot


plot(hist('data/test.hdf5', 'default', 20), "data/out", "Blues_d")
```
